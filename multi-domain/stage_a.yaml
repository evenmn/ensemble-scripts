defaults:
  - data: zarr
  - dataloader: native_grid
  - diagnostics: evaluation
  - datamodule: ens
  - hardware: leonardo
  - graph: o96
  - model: graphtransformer_ens
  - training: ensemble
  - _self_


hydra:  
  searchpath:
    - file:///leonardo_work/DestE_330_25/enordhag/anemoi-core/training/src/anemoi/training/config/
    - file://../../

config_validation: False #True

data:
  frequency: 6h
  resolution: o96
  forcing:
  - cos_latitude
  - cos_longitude
  - sin_latitude
  - sin_longitude
  - cos_julian_day
  - cos_local_time
  - sin_julian_day
  - sin_local_time
  - insolation
  - lsm
  - z
  diagnostic:
  - tp
  - ssrd
  - strd
  normalizer:
    max: 
    - z
    none:
    - cos_latitude
    - cos_longitude
    - sin_latitude
    - sin_longitude
    - cos_julian_day
    - cos_local_time
    - sin_julian_day
    - sin_local_time
    - insolation
    - lsm
    - lcc
    - mcc
    - hcc
    - tcc

dataloader:
  dataset: 
    join:
      - dataset: ${hardware.paths.data}/${hardware.files.dataset_atm}
        drop: [cp, slor, sdor, tcw, q_50, q_250, q_600, t_50, t_250, t_600, u_50, u_250, u_600, v_50, v_250, v_600, w_50, w_250, w_600, z_50, z_250, z_600]
      - dataset: ${hardware.paths.data}/${hardware.files.dataset_land}
        select: [lcc, mcc, hcc, tcc, strd, ssrd]
    adjust: [start, end]
  num_workers:
    training: 4
    validation: 4
    test: 4

  limit_batches:
    training: null
    validation: null
    test: null

  prefetch_factor: 2
  validation_rollout: 1

  batch_size:
    training: 1
    validation: 1
    test: 1

  training:
    start: 1979-01-01
    end: 2021-12-31
    #select: [10u, 10v, 2d, 2t, cos_julian_day, cos_latitude, cos_local_time, cos_longitude, hcc, insolation, lcc, lsm, mcc, msl, q_100, q_1000, q_150, q_200, q_250, q_300, q_400, q_50, q_500, q_700, q_850, q_925, sin_julian_day, sin_latitude, sin_local_time, sin_longitude, skt, sp, ssrd, strd, t_100, t_1000, t_150, t_200, t_250, t_300, t_400, t_50, t_500, t_700, t_850, t_925, tcc, tcw, tp, u_100, u_1000, u_150, u_200, u_250, u_300, u_400, u_50, u_500, u_700, u_850, u_925, v_100, v_1000, v_150, v_200, v_250, v_300, v_400, v_50, v_500, v_700, v_850, v_925, w_100, w_1000, w_150, w_200, w_250, w_300, w_400, w_50, w_500, w_700, w_850, w_925, z, z_100, z_1000, z_150, z_200, z_250, z_300, z_400, z_50, z_500, z_700, z_850, z_925]
    reorder: sort
  validation:
    start: 2022-01-01
    end: 2022-12-31
    #select: ${dataloader.training.select}
    reorder: sort
  test:
    start: 2022-01-01
    end: 2022-12-31
    #select: ${dataloader.training.select}
    reorder: sort

diagnostics:
  plot:
    callbacks: []
  log:
    mlflow:
      enabled: True
      offline: True
      authentication: True
      tracking_uri: https://mlflow.ecmwf.int
      experiment_name: metno
      run_name: ens_o96_de330
      system: True
    interval: 10
    wandb:
      entity: null
  
  checkpoint:
    every_n_minutes:
      save_frequency: null
      num_models_saved: 1
    every_n_epochs:
      save_frequency: 1
      num_models_saved: 1
 
hardware:
  files:
    dataset_atm: ERA5/aifs-ea-an-oper-0001-mars-o96-1979-2023-6h-v8.zarr
    dataset_land: ERA5/aifs-ea-an-oper-0001-mars-o96-1979-2023-6h-v3-land.zarr
    graph: o96_5.pt
  num_gpus_per_model: 2
  num_gpus_per_ensemble: 4

graph:
  overwrite: True #False
  
model:
  num_channels: 1024
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0

  bounding:
    - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
      variables:
        - tp
    - _target_: anemoi.models.layers.bounding.HardtanhBounding #[min_val, max_val]
      variables:
        - tcc
        - hcc
        - mcc
        - lcc
      min_val: 0
      max_val: 1

training:
  fork_run_id: null #a42ecfee-4816-4dda-88c6-2ebdbfb3ae37
  run_id: b1fd5a4f615546f1b0578248e5c8353d #faedb9aeab38489b9af2465b0be3670c
  max_epochs: null
  ensemble_size_per_device: 1
  max_steps: 150000
  load_weights_only: False #True
  transfer_learning: False #True
  lr:
    rate: 1.0e-4
    min: 6.0e-6
    warmup: 1000
  training_loss:
    alpha: 0.95
