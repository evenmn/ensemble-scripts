defaults:
- data: zarr
- dataloader: native_grid
- diagnostics: evaluation
- datamodule: ens
- hardware: leonardo
- graph: stretched_grid
- model: graphtransformer_ens
- training: ensemble
- _self_

config_validation: False #True

hydra:  
  output_subdir: null  
  run:  
    dir: .
  searchpath:
    - file:///leonardo_work/DestE_330_25/enordhag/anemoi-core/training/src/anemoi/training/config/
    - file://../../

data:
  frequency: 6h
  resolution: N320
  forcing:
    - lsm
    - cos_julian_day
    - cos_local_time
    - cos_latitude
    - cos_longitude
    - sin_julian_day
    - sin_local_time
    - sin_latitude
    - sin_longitude
    - insolation
    - z
  diagnostic:
    - tp
    - ssrd
    - strd
  normalizer:
    none:
      - lsm
      - cos_julian_day
      - cos_local_time
      - cos_latitude
      - cos_longitude
      - sin_julian_day
      - sin_local_time
      - sin_latitude
      - sin_longitude
      - insolation
      - lcc
      - mcc
      - hcc
      - tcc
    max:
      - z

hardware:
  files:
    graph: n320_2p5k_7p10.pt
    dataset_atm: IFS/aifs-od-an-oper-0001-mars-n320-2019-2023-6h-v6.zarr
    dataset_land: ERA5/aifs-ea-an-oper-0001-mars-n320-1979-2023-6h-v1-land.zarr
    dataset_lam: MEPS/aifs-meps-2.5km-2020-2023-6h-v7.zarr
    dataset: ERA5/aifs-ea-an-oper-0001-mars-n320-1979-2023-6h-v1-land.zarr
  num_gpus_per_ensemble: 8
  num_gpus_per_model: 4

model:
  num_channels: 1024
  keep_batch_sharded: False
  bounding:
    - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
      variables:
        - tp
    - _target_: anemoi.models.layers.bounding.HardtanhBounding #[min_val, max_val]
      variables:
        - tcc
        - hcc
        - mcc
        - lcc
      min_val: 0
      max_val: 1
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0
  processor:
    num_chunks: 4
  encoder:
    num_chunks: 4
  decoder:
    num_chunks: 4


dataloader:
  dataset:
    cutout:
      - dataset: ${hardware.paths.data}/${hardware.files.dataset_lam}
        reorder: sort
        trim_edge: 50
      - dataset:
          join:
            - dataset: ${hardware.paths.data}/${hardware.files.dataset_atm}
            - dataset: ${hardware.paths.data}/${hardware.files.dataset_land}
              select: [lcc, mcc, hcc, tcc, strd, ssrd]
          adjust: [start, end]
          drop: [sdor, slor, cp, u_600, v_600, w_600, q_600, z_600, t_600]
        reorder: sort
    min_distance_km: 0
    adjust: all

  num_workers:
    training: 4
    validation: 4
    test: 4
  batch_size:
    training: 1
    validation: 1
    test: 1
  limit_batches:
    training: null
    validation: null
  training:
    start: 2020-01-01
    end: 2022-05-31
    select: [10u, 10v, 2d, 2t, cos_julian_day, cos_latitude, cos_local_time, cos_longitude, hcc, insolation, lcc, lsm, mcc, msl, q_100, q_1000, q_150, q_200, q_250, q_300, q_400, q_50, q_500, q_700, q_850, q_925, sin_julian_day, sin_latitude, sin_local_time, sin_longitude, skt, sp, ssrd, strd, t_100, t_1000, t_150, t_200, t_250, t_300, t_400, t_50, t_500, t_700, t_850, t_925, tcc, tcw, tp, u_100, u_1000, u_150, u_200, u_250, u_300, u_400, u_50, u_500, u_700, u_850, u_925, v_100, v_1000, v_150, v_200, v_250, v_300, v_400, v_50, v_500, v_700, v_850, v_925, w_100, w_1000, w_150, w_200, w_250, w_300, w_400, w_50, w_500, w_700, w_850, w_925, z, z_100, z_1000, z_150, z_200, z_250, z_300, z_400, z_50, z_500, z_700, z_850, z_925]
    reorder: sort
  validation:
    start: 2022-06-01
    end: 2023-12-31
  test:
    start: 2022-06-01
    end: 2023-12-31

graph:
  overwrite: True
  nodes:
    hidden:
      node_builder:
        lam_resolution: 10
        global_resolution: 7
        margin_radius_km: 11


training:
  fork_run_id: a7390afe-cbd8-4bea-b375-8411f39cfee3
  run_id: null
  ensemble_size_per_device: 1
  max_epochs: null
  max_steps: 10000 # 10000 r1, 1000 r2
  load_weights_only: True
  transfer_learning: True
  lr:
    rate: 3.75e-5  # 3.75e-5 r1, 3.75e-6 r2
    min: 8.0e-6
    warmup: 1000  # 1000 r1, 100 r2
  training_loss:
    _target_: anemoi.training.losses.combined.CombinedLoss
    losses:
        - _target_: anemoi.training.losses.AlmostFairKernelCRPS
          alpha: 0.95
          scalers: ['pressure_level', 'general_variable', 'nan_mask_weights', 'node_weights']
        - _target_: anemoi.training.losses.CRPSFFTLoss
          xdim: 849
          ydim: 969
          fft: True
          scalers: ['pressure_level', 'general_variable', 'nan_mask_weights']
    scalers: ['*']
    loss_weights: [1.0, 0.1]
  rollout:
    start: 1
    epoch_increment: 0
    max: 1

diagnostics:
  plot:
    callbacks: []
  log:
    interval: 10
    wandb:
      entity: null
    mlflow:
      enabled: True
      offline: True
      authentication: False
      experiment_name: metno
      tracking_uri: https://mlflow.ecmwf.int
      run_name: ens_test
  checkpoint:
    every_n_minutes:
      save_frequency: 30
      num_models_saved: 1
    every_n_epochs:
      save_frequency: 1
      num_models_saved: 1
    every_n_train_steps:
      save_frequency: 100
