defaults:
  - data: zarr
  - dataloader: native_grid
  - diagnostics: evaluation
  - datamodule: ens
  - hardware: leonardo
  - graph: n320
  - model: graphtransformer_ens
  - training: ensemble
  - _self_


hydra:  
  output_subdir: null  
  run:  
    dir: .
  searchpath:
    - file:///leonardo_work/DestE_330_25/enordhag/anemoi-core/training/src/anemoi/training/config/
    - file://../../

config_validation: False

data:
  frequency: 6h
  resolution: n320
  forcing:
  - "cos_latitude"
  - "cos_longitude"
  - "sin_latitude"
  - "sin_longitude"
  - "cos_julian_day"
  - "cos_local_time"
  - "sin_julian_day"
  - "sin_local_time"
  - "insolation"
  - "lsm"
  - "z"
  diagnostic:
  - "tp"
  - "ssrd"
  - "strd"
  normalizer:
    max:
    - "z"
    none:
    - "cos_latitude"
    - "cos_longitude"
    - "sin_latitude"
    - "sin_longitude"
    - "cos_julian_day"
    - "cos_local_time"
    - "sin_julian_day"
    - "sin_local_time"
    - "insolation"
    - "lsm"
    - "lcc"
    - "mcc"
    - "hcc"
    - "tcc"

dataloader:
  dataset:
    join:
      - dataset: ${hardware.paths.data}/${hardware.files.dataset_atm}
      - dataset: ${hardware.paths.data}/${hardware.files.dataset_land}
        select: ["lcc", "mcc", "hcc", "tcc", "strd", "ssrd"]
    adjust: ["start", "end"]
  num_workers:
    training: 4
    validation: 4
    test: 4

  limit_batches:
    training: 500 #null
    validation: null
    test: null

  prefetch_factor: 2
  validation_rollout: 1

  batch_size:
    training: 1
    validation: 1
    test: 1

  training:
    start: 1979-01-01
    end: 2021-12-31
    select: ['10u', '10v', '2d', '2t', 'cos_julian_day', 'cos_latitude', 'cos_local_time', 'cos_longitude', 'hcc', 'insolation', 'lcc', 'lsm', 'mcc', 'msl', 'q_100', 'q_1000', 'q_150', 'q_200', 'q_250', 'q_300', 'q_400', 'q_50', 'q_500', 'q_700', 'q_850', 'q_925', 'sin_julian_day', 'sin_latitude', 'sin_local_time', 'sin_longitude', 'skt', 'sp', 'ssrd', 'strd', 't_100', 't_1000', 't_150', 't_200', 't_250', 't_300', 't_400', 't_50', 't_500', 't_700', 't_850', 't_925', 'tcc', 'tcw', 'tp', 'u_100', 'u_1000', 'u_150', 'u_200', 'u_250', 'u_300', 'u_400', 'u_50', 'u_500', 'u_700', 'u_850', 'u_925', 'v_100', 'v_1000', 'v_150', 'v_200', 'v_250', 'v_300', 'v_400', 'v_50', 'v_500', 'v_700', 'v_850', 'v_925', 'w_100', 'w_1000', 'w_150', 'w_200', 'w_250', 'w_300', 'w_400', 'w_50', 'w_500', 'w_700', 'w_850', 'w_925', 'z', 'z_100', 'z_1000', 'z_150', 'z_200', 'z_250', 'z_300', 'z_400', 'z_50', 'z_500', 'z_700', 'z_850', 'z_925']
    reorder: sort

  validation:
    start: 2022-01-01
    end: 2022-12-31
    select: ${dataloader.training.select}
    reorder: sort
  test:
    start: 2022-01-01
    end: 2022-12-31
    select: ${dataloader.training.select}
    reorder: sort

diagnostics:
  plot:
    callbacks: []
  log:
    mlflow:
      enabled: True
      offline: True
      authentication: True
      tracking_uri: https://mlflow.ecmwf.int
      experiment_name: 'metno'
      run_name: ens_n320_adamw_r2
      system: True
    interval: 100
    wandb:
      entity: null

  checkpoint:
    every_n_minutes:
      save_frequency: 30
      num_models_saved: 1
    every_n_epochs:
      save_frequency: 1
      num_models_saved: -1

hardware:
  files:
    dataset_atm: ERA5/aifs-ea-an-oper-0001-mars-n320-1979-2022-6h-v6.zarr
    dataset_land: ERA5/aifs-ea-an-oper-0001-mars-n320-1979-2023-6h-v1-land.zarr
    graph: n320_7.pt
  num_gpus_per_model: 4
  num_gpus_per_ensemble: 8

graph:
  overwrite: False

model:
  num_channels: 1024
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0

  bounding:
    - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
      variables:
        - tp
    - _target_: anemoi.models.layers.bounding.HardtanhBounding #[min_val, max_val]
      variables:
        - tcc
        - hcc
        - mcc
        - lcc
      min_val: 0
      max_val: 1

  processor:
    num_chunks: 8
  encoder: 
    num_chunks: 8
  decoder:
    num_chunks: 8

training:
  run_id: null #e5830fc206564c3782ed38adf1eacdad
  fork_run_id: a4981a77c70a4388a3dff595dc8210f9
  max_epochs: null
  load_weights_only: True
  transfer_learning: True
  ensemble_size_per_device: 1
  max_steps: 30000
  
  lr:
    rate: 6.25e-7
    min: 3e-7
    warmup: 1000
  training_loss:
    alpha: 0.95
  rollout:
    start: 2
    epoch_increment: 0
    max: 2
  optimizer:
    name: AdamW
    zero: False # use ZeroRedundancyOptimizer ; saves memory for larger models
