defaults:
- data: zarr
- dataloader: native_grid
- datamodule: ens
- diagnostics: evaluation
- hardware: example
- graph: stretched_grid
- model: graphtransformer_ens
- training: default
- _self_

config_validation: False

data:
  resolution: N320
  forcing:
    - lsm
    - cos_julian_day
    - cos_local_time
    - cos_latitude
    - cos_longitude
    - sin_julian_day
    - sin_local_time
    - sin_latitude
    - sin_longitude
    - insolation
    - z
  diagnostic:
    - tp
  normalizer:
    none:
      - lsm
      - cos_julian_day
      - cos_local_time
      - cos_latitude
      - cos_longitude
      - sin_julian_day
      - sin_local_time
      - sin_latitude
      - sin_longitude
      - insolation
    max:
      - z

datamodule:
  _target_: anemoi.training.data.datamodule.AnemoiEnsDatasetsDataModule

hardware:
  paths:
    #truncation: /ec/res4/hpcperm/nesl/inter_mat
    truncation: null
    data: /pfs/lustrep4/scratch/project_465000527/anemoi/datasets/
    output: /pfs/lustrep4/scratch/project_465000527/anemoi/experiments/
    graph: /pfs/lustrep4/scratch/project_465000527/anemoi/graphs/
  files:
    #truncation: O96-O32-linear.mat.npz
    #truncation_inv: O32-O96-linear.mat.npz
    truncation: null
    truncation_inv: null
    graph: n320_2p5k_7p10.pt
    dataset: ERA5/aifs-od-an-oper-0001-mars-n320-2019-2023-6h-v6.zarr
    dataset_lam: MEPS/aifs-meps-2.5km-2020-2024-6h-v6.zarr
  accelerator: auto
  num_gpus_per_ensemble: 16
  num_gpus_per_node: ${oc.decode:${oc.env:SLURM_GPUS_PER_NODE}}
  num_nodes: ${oc.decode:${oc.env:SLURM_NNODES}}
  num_gpus_per_model: 8

model:
  output_mask: null
  num_channels: 1024

dataloader:
  dataset:
    cutout:
      - dataset: ${hardware.paths.data}/${hardware.files.dataset_lam}
        reorder: sort
      - dataset: ${hardware.paths.data}/${hardware.files.dataset}
        drop: [sdor, slor, cp, u_600, v_600, w_600, q_600, z_600, t_600]
        reorder: sort
    adjust: all
  num_workers:
    training: 2
    validation: 2
    test: 1
  batch_size:
    training: 1
    validation: 1
    test: 1
  limit_batches:
    training: 132
    validation: null
  training:
    start: 2020-01-01
    end: 2022-12-31
  validation:
    start: 2023-01-01
    end: 2023-12-31
  test:
    start: 2023-01-01
    end: 2023-12-31

training:
  model_task: anemoi.training.train.forecaster.GraphEnsForecaster
  strategy:
    _target_: anemoi.training.distributed.strategy.DDPEnsGroupStrategy
    num_gpus_per_ensemble: ${hardware.num_gpus_per_ensemble}
    num_gpus_per_model: ${hardware.num_gpus_per_model}
  ensemble_size_per_device: 1
  max_epochs: 100
  lr:
    rate: 2.0e-5
    iterations: 13000 # NOTE: When max_epochs < max_steps, scheduler will run for max_steps
    min: 8e-6 #Not scaled by #GPU
    warmup_t: 1000

  precision: bf16-mixed

  optimizer:
    zero: False
    kwargs:
      weight_decay: 0.1
      betas: [0.9, 0.95]
      eps: 1e-7

  pressure_level_scaler:
    _target_: anemoi.training.data.scaling.ReluPressureLevelScaler
    minimum: 0.2
    slope: 0.001

  # loss function for the model
  training_loss:
    # loss class to initialise, can be anything subclassing torch.nn.Module
    _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
    # other kwargs
    scalars: ['variable']
    ignore_nans: False
    alpha: 0.95

  validation_metrics:
    # loss class to initialise, can be anything subclassing torch.nn.Module
    - _target_: anemoi.training.losses.kcrps.KernelCRPS
      # other kwargs
      scalars: []
      ignore_nans: False
      fair: True
    - _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
      scalars: []
      ignore_nans: False
      alpha: 0.95
    - _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
      scalars: []
      ignore_nans: False
      alpha: 1.0

diagnostics:
  plot:
    callbacks: []
  log:
    interval: 4
    wandb:
      entity: 'ecmwf'
    mlflow:
      enabled: True
      offline: True
      experiment_name: 'stretched_ens'
      authentication: False
      tracking_uri: 'https://mlflow.ecmwf.int'
      run_name: 'debug12343'
  profiler: False
  enable_progress_bar: True
