defaults:
- data: zarr
- dataloader: native_grid
- datamodule: ens
- diagnostics: evaluation
- hardware: example
- graph: stretched_grid
- model: graphtransformer_ens
- training: default
- _self_

config_validation: False

data:
  resolution: N320
  forcing:
    - lsm
    - cos_julian_day
    - cos_local_time
    - cos_latitude
    - cos_longitude
    - sin_julian_day
    - sin_local_time
    - sin_latitude
    - sin_longitude
    - insolation
    - z
  diagnostic:
    - tp
  normalizer:
    none:
      - lsm
      - cos_julian_day
      - cos_local_time
      - cos_latitude
      - cos_longitude
      - sin_julian_day
      - sin_local_time
      - sin_latitude
      - sin_longitude
      - insolation
    max:
      - z

datamodule:
  _target_: anemoi.training.data.datamodule.AnemoiEnsDatasetsDataModule

hardware:
  paths:
    #truncation: /ec/res4/hpcperm/nesl/inter_mat
    truncation: null
    data: /pfs/lustrep4/scratch/project_465000527/anemoi/datasets/
    output: /pfs/lustrep4/scratch/project_465000527/anemoi/experiments/
    graph: /pfs/lustrep4/scratch/project_465000527/anemoi/graphs/
  files:
    #truncation: O96-O32-linear.mat.npz
    #truncation_inv: O32-O96-linear.mat.npz
    truncation: null
    truncation_inv: null
    graph: cerra_n320_7p9.pt
    dataset_lam: /CERRA/cerra-rr-an-oper-0001-mars-5p5km-1984-2020-3h-v2-rmi.zarr
    dataset_lam_z: /CERRA/cerra-rr-an-oper-0001-mars-5p5km-1984-2020-3h-v2-z_sfc-rmi.zarr
    dataset: ERA5/aifs-ea-an-oper-0001-mars-n320-1979-2022-6h-v6.zarr
  accelerator: auto
  num_gpus_per_ensemble: 16
  num_gpus_per_node: ${oc.decode:${oc.env:SLURM_GPUS_PER_NODE}}
  num_nodes: ${oc.decode:${oc.env:SLURM_NNODES}}
  num_gpus_per_model: 8

graph:
  overwrite: False
  data: "data"
  hidden: "hidden"
  nodes:
    hidden:
      node_builder:
        _target_: anemoi.graphs.nodes.StretchedTriNodes
        lam_resolution: 9
        global_resolution: 7
        reference_node_name: ${graph.data}
        mask_attr_name: cutout_mask
        margin_radius_km: 11

model:
  output_mask: null
  num_channels: 1024
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0
  processor:
    num_noise_channels: 4

dataloader:
  dataset:
    cutout:
      - dataset:
          join:
            - dataset: ${hardware.paths.data}${hardware.files.dataset_lam}
              rename:
                2t_2: 2t
                2d_2: 2d
                10u_10: 10u
                10v_10: 10v
                msl_0: msl
              rescale:
                tp:
                  scale: 0.001
                  offset: 0.0
            - dataset: ${hardware.paths.data}${hardware.files.dataset_lam_z}
          trim_edge: [600,25,400,300]
      - dataset: ${hardware.paths.data}${hardware.files.dataset}
    min_distance_km: 0
    adjust: all
    drop: [u_600, v_600, z_600, t_600, q_600]

  num_workers:
    training: 2
    validation: 2
    test: 1
  batch_size:
    training: 1
    validation: 1
    test: 1
  limit_batches:
    training: 1000
    validation: 10
  training:
    start: 1984-01-01
    end: 2019-12-31
  validation:
    start: 2020-01-01
    end: 2020-12-31
  test:
    start: 2020-01-01
    end: 2020-12-31

training:
  fork_run_id: null
  run_id: cerra
  model_task: anemoi.training.train.forecaster.GraphEnsForecaster
  strategy:
    _target_: anemoi.training.distributed.strategy.DDPEnsGroupStrategy
    num_gpus_per_ensemble: ${hardware.num_gpus_per_ensemble}
    num_gpus_per_model: ${hardware.num_gpus_per_model}
  ensemble_size_per_device: 1
  max_epochs: 151
  lr:
    rate: 2.0e-5
    iterations: 150000 # NOTE: When max_epochs < max_steps, scheduler will run for max_steps
    min: 8.0e-6 #Not scaled by #GPU
    warmup_t: 1000

  precision: bf16-mixed

  optimizer:
    zero: False
    kwargs:
      weight_decay: 0.1
      betas: [0.9, 0.95]
      eps: 1e-7

  pressure_level_scaler:
    _target_: anemoi.training.data.scaling.ReluPressureLevelScaler
    minimum: 0.2
    slope: 0.001

  # loss function for the model
  training_loss:
    # loss class to initialise, can be anything subclassing torch.nn.Module
    _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
    # other kwargs
    scalars: ['variable']
    ignore_nans: False
    alpha: 0.95

  validation_metrics:
    # loss class to initialise, can be anything subclassing torch.nn.Module
    - _target_: anemoi.training.losses.kcrps.KernelCRPS
      # other kwargs
      scalars: []
      ignore_nans: False
      fair: True
    - _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
      scalars: []
      ignore_nans: False
      alpha: 0.95
    - _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
      scalars: []
      ignore_nans: False
      alpha: 1.0

diagnostics:
  plot:
    callbacks: []
  log:
    interval: 4
    wandb:
      entity: 'ecmwf'
    mlflow:
      enabled: False
      offline: True
      experiment_name: 'metno'
      authentication: True
      tracking_uri: 'https://mlflow.ecmwf.int'
      run_name: 'cerra_ens'
  profiler: False
  enable_progress_bar: True
